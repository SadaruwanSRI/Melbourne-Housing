{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b4b3d7f",
   "metadata": {},
   "source": [
    "## <b>Data Loading</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d22f5875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb4d9966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13580 entries, 0 to 13579\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Suburb         13580 non-null  object \n",
      " 1   Address        13580 non-null  object \n",
      " 2   Rooms          13580 non-null  int64  \n",
      " 3   Type           13580 non-null  object \n",
      " 4   Price          13580 non-null  float64\n",
      " 5   Method         13580 non-null  object \n",
      " 6   SellerG        13580 non-null  object \n",
      " 7   Date           13580 non-null  object \n",
      " 8   Distance       13580 non-null  float64\n",
      " 9   Postcode       13580 non-null  float64\n",
      " 10  Bedroom2       13580 non-null  float64\n",
      " 11  Bathroom       13580 non-null  float64\n",
      " 12  Car            13518 non-null  float64\n",
      " 13  Landsize       13580 non-null  float64\n",
      " 14  BuildingArea   7130 non-null   float64\n",
      " 15  YearBuilt      8205 non-null   float64\n",
      " 16  CouncilArea    12211 non-null  object \n",
      " 17  Lattitude      13580 non-null  float64\n",
      " 18  Longtitude     13580 non-null  float64\n",
      " 19  Regionname     13580 non-null  object \n",
      " 20  Propertycount  13580 non-null  float64\n",
      "dtypes: float64(12), int64(1), object(8)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#Load the dataset\n",
    "data = pd.read_csv(\"melb_data.csv\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08233c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select target \n",
    "y = data.Price\n",
    "\n",
    "# To keep thing simple, we will use only neumerical predictors\n",
    "melb_predictors = data.drop([\"Price\"], axis=1)\n",
    "X = melb_predictors.select_dtypes(exclude=[\"object\"])\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038e8b04",
   "metadata": {},
   "source": [
    "### Define Function to Measure Quality of Each Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "801e4dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=10, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589b659c",
   "metadata": {},
   "source": [
    "### Score from Approach 1 (Drop Columns with Missing Values)\n",
    "\n",
    "Since we are working with both training and validation sets, we are careful to drop the same columns in both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cac6ce56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Car', 'BuildingArea', 'YearBuilt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
    "cols_with_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aa9e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns in trining and validation data\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f78bcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop columns with missing values):\n",
      "183550.22137772635\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 1 (Drop columns with missing values):\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61a6d54",
   "metadata": {},
   "source": [
    "### Score from Approach 2 (Imputation)\n",
    "\n",
    "Now we’ll try handling missing data by using SimpleImputer, which replaces missing values in each column with that column’s mean.\n",
    "\n",
    "This is an easy technique, but it often works surprisingly well (though results depend on the dataset). While there are more advanced imputation methods—like regression imputation—these more complicated approaches usually don’t improve performance when you’re using powerful machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cf1eec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Imputation):\n",
      "178166.46269899711\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputation\n",
    "my_imputer = SimpleImputer(strategy=\"mean\")\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "# Imputation removed column names, so we need to set them back\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns\n",
    "\n",
    "print(\"MAE from Approach 2 (Imputation):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04849fce",
   "metadata": {},
   "source": [
    "We see that Approach 2 has lower MAE than Approach 1, so Approach 2 performed better on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e781cc5f",
   "metadata": {},
   "source": [
    "### Score from Approach 3 (An Extension to Imputation)¶\n",
    "Next, we impute the missing values, while also keeping track of which values were imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15c424ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 3 (An Extension to Imputation):\n",
      "178927.503183954\n"
     ]
    }
   ],
   "source": [
    "# Make copy to avoid changing original data (when imputing)\n",
    "X_train_plus = X_train.copy()\n",
    "X_valid_plus = X_valid.copy()\n",
    "\n",
    "# Make new column indicating what will be imputed\n",
    "for col in cols_with_missing:\n",
    "    X_train_plus[col+'_was_missing'] = X_train_plus[col].isnull()\n",
    "    X_valid_plus[col+'_was_missing'] = X_valid_plus[col].isnull()\n",
    "\n",
    "# Impute the missing values\n",
    "my_imputer = SimpleImputer(strategy=\"mean\")\n",
    "imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n",
    "imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n",
    "\n",
    "# Set the column names back\n",
    "imputed_X_train_plus.columns = X_train_plus.columns\n",
    "imputed_X_valid_plus.columns = X_valid_plus.columns\n",
    "\n",
    "print(\"MAE from Approach 3 (An Extension to Imputation):\")\n",
    "print(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcef52b",
   "metadata": {},
   "source": [
    "As we can see, Approach 3 performed slightly worse than Approach 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
